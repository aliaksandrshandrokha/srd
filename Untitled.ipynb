{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c0e414-09d4-449a-929d-1918414bc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC, GradientBoostingClassifier as GBC\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier as CART\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c4befd-d618-4d69-9e3b-79850157a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "train_data = pd.read_csv('IPA.csv')\n",
    "test_data = pd.read_csv('IPA_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4fb579-9b69-4f03-91e1-d0aa1941aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przekształcenie kolumny IsIPA na wartości liczbowe (0/1)\n",
    "train_data['IsIPA'] = train_data['IsIPA'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e75aaf1b-b8ac-448f-b7de-5cb73af44047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział danych na zbiór treningowy i walidacyjny\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(['IsIPA', 'UserId'], axis=1),\n",
    "    train_data['IsIPA'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6b8da5-3a47-4afc-a4a7-53c316e8eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] END .....n_estimators=153, subsample=0.2596745008740101; total time=   0.0s\n",
      "[CV] END .....n_estimators=153, subsample=0.2596745008740101; total time=   0.0s\n",
      "[CV] END .....n_estimators=153, subsample=0.2596745008740101; total time=   0.0s\n",
      "[CV] END .....n_estimators=323, subsample=0.8077107411409182; total time=   0.0s\n",
      "[CV] END .....n_estimators=323, subsample=0.8077107411409182; total time=   0.0s\n",
      "[CV] END .....n_estimators=323, subsample=0.8077107411409182; total time=   0.0s\n",
      "[CV] END ....n_estimators=230, subsample=0.49791904504962026; total time=   0.0s\n",
      "[CV] END ....n_estimators=230, subsample=0.49791904504962026; total time=   0.0s\n",
      "[CV] END ....n_estimators=230, subsample=0.49791904504962026; total time=   0.0s\n",
      "[CV] END .....n_estimators=336, subsample=0.7639755509613092; total time=   0.0s\n",
      "[CV] END .....n_estimators=336, subsample=0.7639755509613092; total time=   0.0s\n",
      "[CV] END .....n_estimators=336, subsample=0.7639755509613092; total time=   0.0s\n",
      "[CV] END .....n_estimators=214, subsample=0.5209380844836324; total time=   0.0s\n",
      "[CV] END .....n_estimators=214, subsample=0.5209380844836324; total time=   0.0s\n",
      "[CV] END .....n_estimators=214, subsample=0.5209380844836324; total time=   0.0s\n",
      "[CV] END .....n_estimators=287, subsample=0.8087860792347457; total time=   0.0s\n",
      "[CV] END .....n_estimators=287, subsample=0.8087860792347457; total time=   0.0s\n",
      "[CV] END .....n_estimators=287, subsample=0.8087860792347457; total time=   0.0s\n",
      "[CV] END ....n_estimators=294, subsample=0.19573406720253117; total time=   0.0s\n",
      "[CV] END ....n_estimators=294, subsample=0.19573406720253117; total time=   0.0s\n",
      "[CV] END ....n_estimators=294, subsample=0.19573406720253117; total time=   0.0s\n",
      "[CV] END ....n_estimators=112, subsample=0.23503608739867632; total time=   0.0s\n",
      "[CV] END ....n_estimators=112, subsample=0.23503608739867632; total time=   0.0s\n",
      "[CV] END ....n_estimators=112, subsample=0.23503608739867632; total time=   0.0s\n",
      "[CV] END ....n_estimators=265, subsample=0.07558877361084604; total time=   0.0s\n",
      "[CV] END ....n_estimators=265, subsample=0.07558877361084604; total time=   0.0s\n",
      "[CV] END ....n_estimators=265, subsample=0.07558877361084604; total time=   0.0s\n",
      "[CV] END .....n_estimators=355, subsample=0.9797016599471063; total time=   0.0s\n",
      "[CV] END .....n_estimators=355, subsample=0.9797016599471063; total time=   0.0s\n",
      "[CV] END .....n_estimators=355, subsample=0.9797016599471063; total time=   0.0s\n",
      "[CV] END .....n_estimators=279, subsample=0.7085227415846852; total time=   0.0s\n",
      "[CV] END .....n_estimators=279, subsample=0.7085227415846852; total time=   0.0s\n",
      "[CV] END .....n_estimators=279, subsample=0.7085227415846852; total time=   0.0s\n",
      "[CV] END .....n_estimators=264, subsample=0.7441715536018553; total time=   0.0s\n",
      "[CV] END .....n_estimators=264, subsample=0.7441715536018553; total time=   0.0s\n",
      "[CV] END .....n_estimators=264, subsample=0.7441715536018553; total time=   0.0s\n",
      "[CV] END .....n_estimators=317, subsample=0.3303134709465667; total time=   0.0s\n",
      "[CV] END .....n_estimators=317, subsample=0.3303134709465667; total time=   0.0s\n",
      "[CV] END .....n_estimators=317, subsample=0.3303134709465667; total time=   0.0s\n",
      "[CV] END .....n_estimators=104, subsample=0.8570462918749503; total time=   0.0s\n",
      "[CV] END .....n_estimators=104, subsample=0.8570462918749503; total time=   0.0s\n",
      "[CV] END .....n_estimators=104, subsample=0.8570462918749503; total time=   0.0s\n",
      "[CV] END ....n_estimators=101, subsample=0.16846308456229497; total time=   0.0s\n",
      "[CV] END ....n_estimators=101, subsample=0.16846308456229497; total time=   0.0s\n",
      "[CV] END ....n_estimators=101, subsample=0.16846308456229497; total time=   0.0s\n",
      "[CV] END ....n_estimators=266, subsample=0.32963919233430405; total time=   0.0s\n",
      "[CV] END ....n_estimators=266, subsample=0.32963919233430405; total time=   0.0s\n",
      "[CV] END ....n_estimators=266, subsample=0.32963919233430405; total time=   0.0s\n",
      "[CV] END ...n_estimators=334, subsample=0.016557926677581936; total time=   0.0s\n",
      "[CV] END ...n_estimators=334, subsample=0.016557926677581936; total time=   0.0s\n",
      "[CV] END ...n_estimators=334, subsample=0.016557926677581936; total time=   0.0s\n",
      "[CV] END .....n_estimators=295, subsample=0.5416673361189488; total time=   0.0s\n",
      "[CV] END .....n_estimators=295, subsample=0.5416673361189488; total time=   0.0s\n",
      "[CV] END .....n_estimators=295, subsample=0.5416673361189488; total time=   0.0s\n",
      "[CV] END ....n_estimators=243, subsample=0.06892189164374374; total time=   0.0s\n",
      "[CV] END ....n_estimators=243, subsample=0.06892189164374374; total time=   0.0s\n",
      "[CV] END ....n_estimators=243, subsample=0.06892189164374374; total time=   0.0s\n",
      "[CV] END .....n_estimators=251, subsample=0.7391341195245609; total time=   0.0s\n",
      "[CV] END .....n_estimators=251, subsample=0.7391341195245609; total time=   0.0s\n",
      "[CV] END .....n_estimators=251, subsample=0.7391341195245609; total time=   0.0s\n",
      "[CV] END .....n_estimators=364, subsample=0.6386908687151124; total time=   0.0s\n",
      "[CV] END .....n_estimators=364, subsample=0.6386908687151124; total time=   0.0s\n",
      "[CV] END .....n_estimators=364, subsample=0.6386908687151124; total time=   0.0s\n",
      "[CV] END .....n_estimators=276, subsample=0.8735059415635466; total time=   0.0s\n",
      "[CV] END .....n_estimators=276, subsample=0.8735059415635466; total time=   0.0s\n",
      "[CV] END .....n_estimators=276, subsample=0.8735059415635466; total time=   0.0s\n",
      "[CV] END .....n_estimators=335, subsample=0.2531419163680855; total time=   0.0s\n",
      "[CV] END .....n_estimators=335, subsample=0.2531419163680855; total time=   0.0s\n",
      "[CV] END .....n_estimators=335, subsample=0.2531419163680855; total time=   0.0s\n",
      "[CV] END .....n_estimators=392, subsample=0.2913647693583745; total time=   0.0s\n",
      "[CV] END .....n_estimators=392, subsample=0.2913647693583745; total time=   0.0s\n",
      "[CV] END .....n_estimators=392, subsample=0.2913647693583745; total time=   0.0s\n",
      "[CV] END .....n_estimators=364, subsample=0.6360408485377851; total time=   0.0s\n",
      "[CV] END .....n_estimators=364, subsample=0.6360408485377851; total time=   0.0s\n",
      "[CV] END .....n_estimators=364, subsample=0.6360408485377851; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 75 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n75 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py\", line 429, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nGradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m dist \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: stats\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m400\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m: stats\u001b[38;5;241m.\u001b[39muniform()}\n\u001b[0;32m      2\u001b[0m tuning_res_gbc \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(GBC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m      3\u001b[0m                                     param_distributions\u001b[38;5;241m=\u001b[39mdist,\n\u001b[0;32m      4\u001b[0m                                     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m                                     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtuning_res_gbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 75 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n75 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py\", line 429, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\aliak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nGradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "dist = {'n_estimators': stats.randint(100, 400), 'subsample': stats.uniform()}\n",
    "tuning_res_gbc = RandomizedSearchCV(GBC(random_state=42),\n",
    "                                    param_distributions=dist,\n",
    "                                    scoring='accuracy',\n",
    "                                    n_iter=25,\n",
    "                                    n_jobs=1,\n",
    "                                    cv=3,\n",
    "                                    verbose=2)\n",
    "tuning_res_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481da106-cf79-4903-b309-12000d15f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuning_res_gbc.best_params_)\n",
    "Best_GBT = tuning_res_gbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d99cc-3ca9-4a5f-b58c-22c4bfa0d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feature_importance = Best_GBT.feature_importances_\n",
    "# Make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "num_feat = 6\n",
    "\n",
    "plt.figure(figsize=[12, 8])\n",
    "plt.barh(pos[-num_feat:],\n",
    "         feature_importance[sorted_idx][-num_feat:],\n",
    "         align='center',\n",
    "         alpha=0.75)\n",
    "plt.yticks(pos[-num_feat:], X_train.columns[sorted_idx][-num_feat:])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34399144-dbd9-4e68-ad73-95b3d5643986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feature_importance = Best_GBT.feature_importances_\n",
    "# Make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "num_feat = 6\n",
    "\n",
    "plt.figure(figsize=[12, 8])\n",
    "plt.barh(pos[-num_feat:],\n",
    "         feature_importance[sorted_idx][-num_feat:],\n",
    "         align='center',\n",
    "         alpha=0.75)\n",
    "plt.yticks(pos[-num_feat:], X_train.columns[sorted_idx][-num_feat:])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93e32f-6eb3-412b-9429-9fbd6df86c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['CART', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "        accuracies_test,\n",
    "        color=['red', 'green', 'blue'],\n",
    "        alpha=0.75)\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fad71a-8e96-4e69-b706-0c82f2c0a687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292f8e4-28e3-46e7-8248-500d38261911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22caa215-2b75-4ee7-818e-1d067aaa66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "train_data = pd.read_csv('IPA.csv')\n",
    "test_data = pd.read_csv('IPA_test.csv')\n",
    "\n",
    "# Przekształcenie kolumny IsIPA na wartości liczbowe (0/1)\n",
    "train_data['IsIPA'] = train_data['IsIPA'].astype(int)\n",
    "\n",
    "# Podział danych na zbiór treningowy i walidacyjny\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(['IsIPA', 'UserId'], axis=1),\n",
    "    train_data['IsIPA'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline do obsługi brakujących danych, skalowania, i klasyfikacji\n",
    "model_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "# Hiperparametry do optymalizacji\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20, 30],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Optymalizacja hiperparametrów\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Wydrukowanie najlepszych parametrów\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predykcja na zbiorze walidacyjnym\n",
    "y_val_pred = grid_search.predict(X_val)\n",
    "\n",
    "# Wartość F1 na zbiorze walidacyjnym\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "print(\"F1 Score on Validation Set:\", f1_val)\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "test_predictions = grid_search.predict(test_data.drop(['UserId'], axis=1))\n",
    "\n",
    "# Zapisanie predykcji do pliku CSV\n",
    "test_data['IsIPA'] = test_predictions\n",
    "test_data[['UserId', 'IsIPA']].to_csv('IPA_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
